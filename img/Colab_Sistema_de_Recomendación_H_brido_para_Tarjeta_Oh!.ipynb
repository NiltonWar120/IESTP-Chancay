{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title # 1. Configuración del Entorno e Instalación de Dependencias\n",
        "# Se instalan las versiones más recientes de las librerías necesarias.\n",
        "# TensorFlow Recommenders para la etapa de recuperación.\n",
        "# Ya no se necesita tensorflow-ranking.\n",
        "!pip install -q --upgrade tensorflow-recommenders\n",
        "\n",
        "# Importar las librerías principales\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "# Imprimir versiones para asegurar compatibilidad\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"TFRS Version: {tfrs.__version__}\")\n",
        "\n",
        "\n",
        "#@title # 2. Simulación de Datos (Modelo de Datos Proporcionado)\n",
        "# --- Parámetros de la Simulación ---\n",
        "NUM_CLIENTES = 2000\n",
        "NUM_ESTABLECIMIENTOS = 1000\n",
        "NUM_TRANSACCIONES = 150000\n",
        "\n",
        "# --- Tabla: Clientes ---\n",
        "print(\"Generando tabla de Clientes...\")\n",
        "cliente_ids = [f\"cliente_{i}\" for i in range(NUM_CLIENTES)]\n",
        "edades = np.random.randint(18, 70, size=NUM_CLIENTES)\n",
        "generos = np.random.choice(['M', 'F'], NUM_CLIENTES, p=[0.5, 0.5])\n",
        "segmentos = np.random.choice(['Premium', 'Clasico', 'Nuevo'], NUM_CLIENTES, p=[0.15, 0.65, 0.2])\n",
        "clientes_df = pd.DataFrame({\n",
        "    'id_cliente': cliente_ids,\n",
        "    'edad': edades,\n",
        "    'genero': generos,\n",
        "    'segmento_cliente': segmentos\n",
        "})\n",
        "\n",
        "# --- Tabla: Establecimientos ---\n",
        "print(\"Generando tabla de Establecimientos...\")\n",
        "establecimiento_ids = [f\"est_{i}\" for i in range(NUM_ESTABLECIMIENTOS)]\n",
        "rubros = ['Restaurante', 'Grifo', 'Retail', 'Entretenimiento', 'Salud', 'Servicios']\n",
        "sub_rubros_map = {\n",
        "    'Restaurante': ['Comida Rapida', 'Gourmet', 'Cafeteria', 'Polleria'],\n",
        "    'Grifo': ['Gasohol 95', 'Gasohol 90', 'Diesel', 'Tienda Conveniencia'],\n",
        "    'Retail': ['Supermercado', 'Tienda por Departamento', 'Farmacia', 'Ferreteria'],\n",
        "    'Entretenimiento': ['Cine', 'Casino', 'Teatro', 'Bowling'],\n",
        "    'Salud': ['Clinica', 'Laboratorio', 'Optica'],\n",
        "    'Servicios': ['Peluqueria', 'Lavanderia', 'Gimnasio']\n",
        "}\n",
        "distritos_lima = ['Miraflores', 'San Isidro', 'Surco', 'La Molina', 'San Borja', 'Lince', 'Pueblo Libre']\n",
        "\n",
        "establecimientos_data = []\n",
        "for est_id in establecimiento_ids:\n",
        "    rubro = np.random.choice(rubros, p=[0.3, 0.15, 0.3, 0.1, 0.1, 0.05])\n",
        "    sub_rubro = np.random.choice(sub_rubros_map[rubro])\n",
        "    distrito = np.random.choice(distritos_lima)\n",
        "    establecimientos_data.append([est_id, f\"Local {est_id.split('_')[1]}\", rubro, sub_rubro, 'Lima', 'Lima', distrito])\n",
        "\n",
        "establecimientos_df = pd.DataFrame(establecimientos_data, columns=[\n",
        "    'id_establecimiento', 'nombre_establecimiento', 'rubro', 'sub_rubro',\n",
        "    'departamento', 'provincia', 'distrito'\n",
        "])\n",
        "\n",
        "# --- Tabla: Transacciones ---\n",
        "print(\"Generando tabla de Transacciones...\")\n",
        "tx_cliente_ids = np.random.choice(cliente_ids, NUM_TRANSACCIONES)\n",
        "tx_establecimiento_ids = np.random.choice(establecimiento_ids, NUM_TRANSACCIONES)\n",
        "montos = np.round(np.random.lognormal(mean=3.5, sigma=1.0, size=NUM_TRANSACCIONES) + 5, 2)\n",
        "timestamps = np.random.randint(1641013200, 1704085199, size=NUM_TRANSACCIONES) # Transacciones en 2022-2023\n",
        "cuotas = np.random.choice([0, 1, 3, 6, 12], NUM_TRANSACCIONES, p=[0.6, 0.1, 0.15, 0.1, 0.05])\n",
        "\n",
        "transacciones_df = pd.DataFrame({\n",
        "    'id_cliente': tx_cliente_ids,\n",
        "    'id_establecimiento': tx_establecimiento_ids,\n",
        "    'monto_compra': montos,\n",
        "    'fecha_compra': pd.to_datetime(timestamps, unit='s'),\n",
        "    'numero_cuotas': cuotas\n",
        "})\n",
        "transacciones_df = transacciones_df.drop_duplicates(subset=['id_cliente', 'id_establecimiento', 'fecha_compra']).reset_index(drop=True)\n",
        "transacciones_df['id_transaccion'] = [f\"tx_{i}\" for i in range(len(transacciones_df))]\n",
        "\n",
        "\n",
        "# --- Creación del DataFrame Unificado para Entrenamiento ---\n",
        "print(\"Unificando tablas para el modelo...\")\n",
        "full_df = transacciones_df.merge(clientes_df, on='id_cliente').merge(establecimientos_df, on='id_establecimiento')\n",
        "\n",
        "print(\"\\n--- Muestra de la Tabla Clientes ---\")\n",
        "print(clientes_df.head())\n",
        "print(f\"\\nTotal de clientes: {len(clientes_df)}\")\n",
        "\n",
        "print(\"\\n--- Muestra de la Tabla Establecimientos ---\")\n",
        "print(establecimientos_df.head())\n",
        "print(f\"\\nTotal de establecimientos: {len(establecimientos_df)}\")\n",
        "\n",
        "print(\"\\n--- Muestra de la Tabla Transacciones ---\")\n",
        "print(transacciones_df.head())\n",
        "print(f\"\\nTotal de transacciones: {len(transacciones_df)}\")\n",
        "\n",
        "print(\"\\n--- Muestra del DataFrame Unificado para Modelado ---\")\n",
        "print(full_df.head())\n",
        "\n",
        "\n",
        "#@title # 3. Etapa 1: Recuperación con TensorFlow Recommenders (TFRS)\n",
        "\n",
        "# --- 3.1 Preparación de Datos para TFRS ---\n",
        "ratings_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    dict(transacciones_df[['id_cliente', 'id_establecimiento']])\n",
        ")\n",
        "establecimientos_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    dict(establecimientos_df[['id_establecimiento']])\n",
        ")\n",
        "\n",
        "cliente_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "cliente_ids_vocabulary.adapt(ratings_ds.map(lambda x: x[\"id_cliente\"]))\n",
        "\n",
        "establecimiento_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "establecimiento_ids_vocabulary.adapt(establecimientos_ds.map(lambda x: x[\"id_establecimiento\"]))\n",
        "\n",
        "\n",
        "# --- 3.2 Construcción del Modelo de Dos Torres ---\n",
        "embedding_dim = 64\n",
        "\n",
        "cliente_model = tf.keras.Sequential([\n",
        "    cliente_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(cliente_ids_vocabulary.vocabulary_size(), embedding_dim)\n",
        "])\n",
        "\n",
        "establecimiento_model = tf.keras.Sequential([\n",
        "    establecimiento_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(establecimiento_ids_vocabulary.vocabulary_size(), embedding_dim)\n",
        "])\n",
        "\n",
        "# --- 3.3 Definición de la Tarea de Recuperación y Entrenamiento ---\n",
        "retrieval_task = tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(\n",
        "        candidates=establecimientos_ds.batch(128).map(establecimiento_model)\n",
        "    )\n",
        ")\n",
        "\n",
        "class TwoTowerRetrievalModel(tfrs.Model):\n",
        "    def __init__(self, user_model, item_model, task):\n",
        "        super().__init__()\n",
        "        self.user_model = user_model\n",
        "        self.item_model = item_model\n",
        "        self.task = task\n",
        "\n",
        "    def compute_loss(self, data: Dict, training=False) -> tf.Tensor:\n",
        "        user_embeddings = self.user_model(data[\"id_cliente\"])\n",
        "        positive_item_embeddings = self.item_model(data[\"id_establecimiento\"])\n",
        "        return self.task(user_embeddings, positive_item_embeddings)\n",
        "\n",
        "retrieval_model = TwoTowerRetrievalModel(cliente_model, establecimiento_model, retrieval_task)\n",
        "retrieval_model.compile(optimizer=tf.keras.optimizers.Adgrad(learning_rate=0.1))\n",
        "\n",
        "cached_train = ratings_ds.shuffle(len(transacciones_df)).batch(8192).cache()\n",
        "\n",
        "print(\"\\nIniciando entrenamiento del modelo de RECUPERACIÓN...\")\n",
        "retrieval_model.fit(cached_train, epochs=3)\n",
        "print(\"Entrenamiento de recuperación completado.\")\n",
        "\n",
        "\n",
        "# --- 3.4 Generación de Candidatos ---\n",
        "retrieval_index = tfrs.layers.ann.BruteForce(retrieval_model.user_model)\n",
        "retrieval_index.index_from_dataset(\n",
        "    tf.data.Dataset.from_tensor_slices(\n",
        "        np.unique(establecimientos_df['id_establecimiento'])\n",
        "    ).batch(100).map(lambda x: (x, retrieval_model.item_model(x)))\n",
        ")\n",
        "\n",
        "test_cliente_id = \"cliente_150\"\n",
        "print(f\"\\n--- Generando candidatos para el cliente: {test_cliente_id} ---\")\n",
        "_, candidate_establecimientos = retrieval_index(tf.constant([test_cliente_id]))\n",
        "\n",
        "print(f\"Top 10 candidatos recuperados para {test_cliente_id}:\")\n",
        "for est in candidate_establecimientos[0, :10].numpy():\n",
        "    print(est.decode())\n",
        "\n",
        "\n",
        "#@title # 4. Etapa 2: Clasificación con Keras Puro (Enfoque Pairwise)\n",
        "\n",
        "# --- 4.1 Preparación de Datos para el Modelo de Ranking ---\n",
        "print(\"\\nPreparando datos para el modelo de CLASIFICACIÓN...\")\n",
        "\n",
        "# Crear un mapeo de ID de establecimiento a sus características para búsqueda rápida\n",
        "establecimiento_features_map = establecimientos_df.set_index('id_establecimiento').to_dict('index')\n",
        "\n",
        "# Crear un mapeo de ID de cliente a sus características\n",
        "cliente_features_map = clientes_df.set_index('id_cliente').to_dict('index')\n",
        "\n",
        "# Agrupar transacciones por cliente\n",
        "interactions_by_client = full_df.groupby('id_cliente')['id_establecimiento'].apply(list).to_dict()\n",
        "\n",
        "# Crear el dataset de entrenamiento\n",
        "# Cada ejemplo consistirá en: (características_cliente, características_establecimiento_positivo, características_establecimiento_negativo)\n",
        "def generate_training_data():\n",
        "    all_establecimiento_ids = establecimientos_df['id_establecimiento'].unique()\n",
        "    for client_id, positive_items in interactions_by_client.items():\n",
        "        client_features = cliente_features_map[client_id]\n",
        "        for positive_item_id in positive_items:\n",
        "            positive_item_features = establecimiento_features_map[positive_item_id]\n",
        "\n",
        "            # Muestrear un item negativo (uno con el que el cliente NO ha interactuado)\n",
        "            negative_item_id = np.random.choice(all_establecimiento_ids)\n",
        "            while negative_item_id in positive_items:\n",
        "                negative_item_id = np.random.choice(all_establecimiento_ids)\n",
        "            negative_item_features = establecimiento_features_map[negative_item_id]\n",
        "\n",
        "            yield {\n",
        "                # Features de cliente\n",
        "                \"segmento_cliente\": client_features['segmento_cliente'],\n",
        "                \"edad\": client_features['edad'],\n",
        "                # Features del item positivo\n",
        "                \"pos_rubro\": positive_item_features['rubro'],\n",
        "                \"pos_distrito\": positive_item_features['distrito'],\n",
        "                # Features del item negativo\n",
        "                \"neg_rubro\": negative_item_features['rubro'],\n",
        "                \"neg_distrito\": negative_item_features['distrito'],\n",
        "            }\n",
        "\n",
        "# Crear el tf.data.Dataset\n",
        "ranking_dataset = tf.data.Dataset.from_generator(\n",
        "    generate_training_data,\n",
        "    output_signature={\n",
        "        \"segmento_cliente\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        \"edad\": tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "        \"pos_rubro\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        \"pos_distrito\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        \"neg_rubro\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        \"neg_distrito\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "    }\n",
        ").shuffle(10000).batch(2048).cache()\n",
        "\n",
        "\n",
        "# --- 4.2 Construcción del Modelo de Ranking con Keras ---\n",
        "\n",
        "# El \"scorer\" es una sub-red que calcula la puntuación de un par (cliente, establecimiento)\n",
        "class ScorerModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        embedding_dimension = 32\n",
        "\n",
        "        self.segmento_vocab = tf.keras.layers.StringLookup(vocabulary=np.unique(clientes_df['segmento_cliente']), mask_token=None)\n",
        "        self.segmento_embedding = tf.keras.layers.Embedding(self.segmento_vocab.vocabulary_size(), embedding_dimension)\n",
        "        self.rubro_vocab = tf.keras.layers.StringLookup(vocabulary=np.unique(establecimientos_df['rubro']), mask_token=None)\n",
        "        self.rubro_embedding = tf.keras.layers.Embedding(self.rubro_vocab.vocabulary_size(), embedding_dimension)\n",
        "        self.distrito_vocab = tf.keras.layers.StringLookup(vocabulary=np.unique(establecimientos_df['distrito']), mask_token=None)\n",
        "        self.distrito_embedding = tf.keras.layers.Embedding(self.distrito_vocab.vocabulary_size(), embedding_dimension)\n",
        "\n",
        "        self.edad_normalization = tf.keras.layers.Normalization(axis=None)\n",
        "        self.edad_normalization.adapt(clientes_df['edad'].astype(np.float32))\n",
        "\n",
        "        # Red neuronal densa que calcula la puntuación final\n",
        "        self.scorer = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ])\n",
        "\n",
        "    def call(self, features):\n",
        "        segmento_emb = self.segmento_embedding(self.segmento_vocab(features[\"segmento_cliente\"]))\n",
        "        edad_norm = self.edad_normalization(tf.cast(features[\"edad\"], tf.float32))\n",
        "        rubro_emb = self.rubro_embedding(self.rubro_vocab(features[\"rubro\"]))\n",
        "        distrito_emb = self.distrito_embedding(self.distrito_vocab(features[\"distrito\"]))\n",
        "\n",
        "        # Concatenar todas las características\n",
        "        all_features = tf.concat([\n",
        "            segmento_emb,\n",
        "            tf.expand_dims(edad_norm, -1),\n",
        "            rubro_emb,\n",
        "            distrito_emb,\n",
        "        ], axis=-1)\n",
        "\n",
        "        score = self.scorer(all_features)\n",
        "        return score\n",
        "\n",
        "# El modelo de ranking completo que maneja la lógica pairwise\n",
        "class PairwiseRankingModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.scorer = ScorerModel()\n",
        "\n",
        "    def call(self, features):\n",
        "        # En inferencia, solo necesitamos puntuar un item a la vez\n",
        "        return self.scorer(features)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Calcular score para el item positivo\n",
        "            positive_score = self.scorer({\n",
        "                \"segmento_cliente\": data[\"segmento_cliente\"],\n",
        "                \"edad\": data[\"edad\"],\n",
        "                \"rubro\": data[\"pos_rubro\"],\n",
        "                \"distrito\": data[\"pos_distrito\"],\n",
        "            })\n",
        "\n",
        "            # Calcular score para el item negativo\n",
        "            negative_score = self.scorer({\n",
        "                \"segmento_cliente\": data[\"segmento_cliente\"],\n",
        "                \"edad\": data[\"edad\"],\n",
        "                \"rubro\": data[\"neg_rubro\"],\n",
        "                \"distrito\": data[\"neg_distrito\"],\n",
        "            })\n",
        "\n",
        "            # Calcular la pérdida pairwise hinge loss\n",
        "            loss = tf.reduce_mean(tf.maximum(0., 1. - (positive_score - negative_score)))\n",
        "\n",
        "        # Aplicar gradientes\n",
        "        grads = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "# --- 4.3 Entrenamiento del Modelo de Ranking ---\n",
        "ranking_model = PairwiseRankingModel()\n",
        "ranking_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "print(\"\\nIniciando entrenamiento del modelo de CLASIFICACIÓN (Keras Puro)...\")\n",
        "ranking_model.fit(ranking_dataset, epochs=5)\n",
        "print(\"Entrenamiento de clasificación completado.\")\n",
        "\n",
        "\n",
        "#@title # 5. Pipeline de Inferencia Completo: Uniendo Todo\n",
        "def get_recommendations(cliente_id: str, top_n: int = 10):\n",
        "    \"\"\"\n",
        "    Genera recomendaciones personalizadas para un cliente uniendo las etapas\n",
        "    de recuperación y clasificación.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generando recomendaciones para {cliente_id} ---\")\n",
        "\n",
        "    # --- ETAPA 1: RECUPERACIÓN ---\n",
        "    print(\"Paso 1: Recuperando 100 candidatos con el modelo TFRS...\")\n",
        "    _, candidate_establecimientos_tensor = retrieval_index(tf.constant([cliente_id]))\n",
        "    candidate_ids = [p.decode() for p in candidate_establecimientos_tensor[0, :100].numpy()]\n",
        "\n",
        "    # --- ETAPA 2: PREPARACIÓN DE DATOS PARA RANKING ---\n",
        "    print(\"Paso 2: Obteniendo características para el modelo de ranking...\")\n",
        "    cliente_info = clientes_df[clientes_df['id_cliente'] == cliente_id]\n",
        "    if cliente_info.empty:\n",
        "        print(f\"Error: Cliente {cliente_id} no encontrado.\")\n",
        "        return None\n",
        "\n",
        "    candidates_df = establecimientos_df[establecimientos_df['id_establecimiento'].isin(candidate_ids)]\n",
        "\n",
        "    # Crear el diccionario de entrada para el modelo de ranking\n",
        "    num_candidates = len(candidates_df)\n",
        "    ranking_input = {\n",
        "        \"segmento_cliente\": tf.constant([cliente_info['segmento_cliente'].iloc[0]] * num_candidates),\n",
        "        \"edad\": tf.constant([cliente_info['edad'].iloc[0]] * num_candidates, dtype=tf.int64),\n",
        "        \"rubro\": tf.constant(candidates_df['rubro'].values),\n",
        "        \"distrito\": tf.constant(candidates_df['distrito'].values),\n",
        "    }\n",
        "\n",
        "    # --- ETAPA 3: RE-RANKING ---\n",
        "    print(\"Paso 3: Puntuando candidatos con el modelo de Keras...\")\n",
        "    scores = ranking_model(ranking_input)\n",
        "\n",
        "    # --- ETAPA 4: ORDENAMIENTO Y RESULTADO FINAL ---\n",
        "    print(f\"Paso 4: Ordenando y devolviendo los top {top_n} establecimientos.\")\n",
        "    candidates_df['ranking_score'] = scores.numpy()\n",
        "    final_recommendations = candidates_df.sort_values(by='ranking_score', ascending=False).head(top_n)\n",
        "\n",
        "    return final_recommendations\n",
        "\n",
        "# --- Probamos el pipeline completo con un par de clientes de ejemplo ---\n",
        "final_recs = get_recommendations(\"cliente_500\")\n",
        "if final_recs is not None:\n",
        "    print(\"\\n--- RECOMENDACIONES FINALES PARA cliente_500 ---\")\n",
        "    print(final_recs[['id_establecimiento', 'nombre_establecimiento', 'rubro', 'distrito', 'ranking_score']])\n",
        "\n",
        "final_recs_2 = get_recommendations(\"cliente_1820\")\n",
        "if final_recs_2 is not None:\n",
        "    print(\"\\n--- RECOMENDACIONES FINALES PARA cliente_1820 ---\")\n",
        "    print(final_recs_2[['id_establecimiento', 'nombre_establecimiento', 'rubro', 'distrito', 'ranking_score']])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "0dJ7xPXZOOlA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}